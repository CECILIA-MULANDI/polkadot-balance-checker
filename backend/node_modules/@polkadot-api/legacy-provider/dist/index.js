'use strict';

var utils = require('@polkadot-api/utils');
var rxjs = require('rxjs');
var rawClient = require('@polkadot-api/raw-client');
var substrateBindings = require('@polkadot-api/substrate-bindings');

const shareLatest = rxjs.shareReplay({
  refCount: true,
  bufferSize: 1
});

const getBlocks = ({
  allHeads$,
  finalized$: finalizedWire$,
  getHeader$,
  hasher$,
  getRecursiveHeader
}) => {
  const connectedBlocks = {
    blocks: /* @__PURE__ */ new Map(),
    prevFin: "",
    finalized: "",
    best: ""
  };
  const getTree = (root, result = []) => {
    result.push(root);
    connectedBlocks.blocks.get(root).children.forEach((c) => {
      getTree(c, result);
    });
    return result;
  };
  const addBlock = (block) => {
    const { blocks } = connectedBlocks;
    const { hash, parent } = block;
    const me = {
      ...block,
      children: /* @__PURE__ */ new Set(),
      usages: /* @__PURE__ */ new Set()
    };
    blocks.set(hash, me);
    blocks.get(parent)?.children.add(hash);
    return me;
  };
  const setBestFromFinalized = () => {
    connectedBlocks.best = connectedBlocks.finalized;
    let bestHeight = 0;
    const { finalized, blocks } = connectedBlocks;
    getTree(finalized).map((x) => blocks.get(x)).forEach((x) => {
      if (x.number > bestHeight) {
        bestHeight = x.number;
        connectedBlocks.best = x.hash;
      }
    });
  };
  const pendingBlocks = /* @__PURE__ */ new Map();
  const trimPending = (root) => {
    const desc = [...pendingBlocks.get(root).children];
    pendingBlocks.delete(root);
    desc.forEach(trimPending);
  };
  const getPendingTree = (root, result = []) => {
    const me = pendingBlocks.get(root);
    if (!me.header) return result;
    result.push(me.header);
    me.children.forEach((c) => {
      getPendingTree(c, result);
    });
    return result;
  };
  const _newBlocks$ = new rxjs.Subject();
  const onError = (e) => _newBlocks$.error(e);
  const _finalized$ = finalizedWire$.pipe(
    rxjs.concatMap((header, idx) => {
      const { hash } = header;
      if (!idx) {
        addBlock(header);
        connectedBlocks.finalized = connectedBlocks.best = header.hash;
      }
      return connectedBlocks.blocks.has(hash) ? rxjs.of(hash) : _newBlocks$.pipe(
        rxjs.filter((x) => x === hash),
        // some of the following blocks could be prunned b/c of this finalized event.
        // So, we have to make sure that this "batch" of _newBlocks has been flushed.
        rxjs.debounceTime(0),
        rxjs.take(1)
      );
    }),
    rxjs.share()
  );
  allHeads$.subscribe((header) => {
    const { parent, hash } = header;
    if (connectedBlocks.blocks.has(parent)) {
      addBlock(header);
      _newBlocks$.next(hash);
    } else {
      pendingBlocks.set(hash, {
        hash: header.hash,
        header,
        children: /* @__PURE__ */ new Set()
      });
      if (!pendingBlocks.has(parent)) {
        pendingBlocks.set(parent, {
          hash: parent,
          header: null,
          children: /* @__PURE__ */ new Set()
        });
        getRecursiveHeader(parent).pipe(
          rxjs.takeWhile((result) => {
            let me = pendingBlocks.get(result.hash);
            if (!me) return false;
            me.header = result;
            const finalized = connectedBlocks.blocks.get(
              connectedBlocks.finalized
            );
            if (finalized && result.number <= finalized.number) {
              while (pendingBlocks.has(me.header?.parent ?? ""))
                me = pendingBlocks.get(me.header.parent);
              trimPending(me.hash);
              return false;
            }
            if (connectedBlocks.blocks.has(result.parent)) {
              let target = connectedBlocks.blocks.get(result.parent);
              const diff = target.number - finalized.number;
              for (let i = 0; i < diff; i++) {
                const nextTarget = connectedBlocks.blocks.get(target.parent);
                if (!nextTarget) break;
                target = nextTarget;
              }
              if (target === finalized) {
                const pendingOnes = getPendingTree(result.hash);
                pendingOnes.forEach((h) => {
                  pendingBlocks.delete(h.hash);
                  addBlock(h);
                  _newBlocks$.next(h.hash);
                });
              } else trimPending(result.hash);
              return false;
            }
            const pendingParent = pendingBlocks.get(result.parent);
            if (pendingParent) {
              pendingParent.children.add(result.hash);
              return false;
            }
            pendingBlocks.set(result.parent, {
              hash: result.parent,
              header: null,
              children: /* @__PURE__ */ new Set([result.hash])
            });
            return true;
          })
        ).subscribe({ error: onError });
      }
      pendingBlocks.get(parent).children.add(hash);
    }
  }, onError);
  const getFinalizedEvent = () => {
    const prunedBlockHashes = [];
    const finalizedBlockHashes = [];
    const { blocks, finalized, prevFin } = connectedBlocks;
    let current = blocks.get(finalized);
    let prev = blocks.get(current.parent);
    while (prev) {
      finalizedBlockHashes.push(current.hash);
      prev.children.forEach((c) => {
        if (c !== current.hash) getTree(c, prunedBlockHashes);
      });
      current = prev;
      if (current.hash === prevFin) break;
      prev = blocks.get(current.parent);
    }
    finalizedBlockHashes.reverse();
    return { event: "finalized", prunedBlockHashes, finalizedBlockHashes };
  };
  let activeSubscriptions = /* @__PURE__ */ new Set();
  const getNewBlockEvent = (blockHash) => {
    const block = connectedBlocks.blocks.get(blockHash);
    activeSubscriptions.forEach((subId) => {
      block.usages.add(subId);
    });
    return {
      event: "newBlock",
      blockHash,
      parentBlockHash: block.parent,
      newRuntime: block.hasUpgrade ? {} : null
    };
  };
  const tryRemove = (blockHash, up) => {
    const { blocks } = connectedBlocks;
    const block = blocks.get(blockHash);
    if (!block || block.usages.size > 0) return;
    const { parent, children } = block;
    if (up !== true) children.forEach((c) => tryRemove(c, false));
    if (up !== false) tryRemove(parent, true);
    if (!blocks.has(parent) || !block.children.size) {
      blocks.get(parent)?.children.delete(blockHash);
      blocks.delete(blockHash);
    }
  };
  const updates$ = rxjs.merge(
    _newBlocks$.pipe(
      rxjs.map((hash) => ({
        type: "new",
        value: connectedBlocks.blocks.get(hash)
      }))
    ),
    _finalized$.pipe(rxjs.map((hash) => ({ type: "fin", value: hash })))
  ).pipe(
    rxjs.mergeMap((x) => {
      if (x.type === "new") {
        const block = x.value;
        const { hash } = block;
        addBlock(block);
        const result2 = [getNewBlockEvent(hash)];
        if (block.number > connectedBlocks.blocks.get(connectedBlocks.best).number) {
          connectedBlocks.best = hash;
          result2.push({ event: "bestBlockChanged", bestBlockHash: hash });
        }
        return result2;
      }
      connectedBlocks.prevFin = connectedBlocks.finalized;
      connectedBlocks.finalized = x.value;
      let prevBest = connectedBlocks.best;
      setBestFromFinalized();
      const result = [getFinalizedEvent()];
      if (prevBest !== connectedBlocks.best)
        result.unshift({
          event: "bestBlockChanged",
          bestBlockHash: connectedBlocks.best
        });
      return result;
    }),
    rxjs.share()
  );
  const ready$ = _newBlocks$.pipe(
    rxjs.filter(() => !pendingBlocks.size),
    rxjs.take(1),
    rxjs.delay(0),
    // allows for the first bunch of _newBlock events to settle on the latest updated state
    rxjs.map(() => null),
    shareLatest
  );
  const finalized$ = ready$.pipe(
    rxjs.mergeMap(
      () => _finalized$.pipe(
        rxjs.map((hash) => connectedBlocks.blocks.get(hash))
      )
    ),
    shareLatest
  );
  rxjs.merge(updates$, finalized$).subscribe({
    error: onError
  });
  const upstream = (subId) => {
    const getInitialized = () => {
      const { blocks, finalized } = connectedBlocks;
      const finalizedBlockHashes = [];
      let current = blocks.get(finalized);
      while (current && finalizedBlockHashes.length < 10) {
        finalizedBlockHashes.push(current.hash);
        current.usages.add(subId);
        current = blocks.get(current.parent);
      }
      finalizedBlockHashes.reverse();
      return {
        event: "initialized",
        finalizedBlockHashes
      };
    };
    const unpin = (blockHash) => {
      const block = connectedBlocks.blocks.get(blockHash);
      if (block) {
        block.usages.delete(subId);
        tryRemove(blockHash);
      }
    };
    const initialEvents$ = ready$.pipe(
      rxjs.mergeMap(() => {
        const { best, finalized } = connectedBlocks;
        const others = getTree(
          finalized
        ).slice(1).map(getNewBlockEvent);
        if (others.length)
          others.push({
            event: "bestBlockChanged",
            bestBlockHash: best
          });
        return [getInitialized(), ...others];
      })
    );
    return {
      blocks$: rxjs.concat(initialEvents$, updates$).pipe(
        rxjs.tap({
          subscribe: () => {
            activeSubscriptions.add(subId);
          },
          finalize: () => {
            activeSubscriptions.delete(subId);
          }
        }),
        rxjs.share()
      ),
      getHeader: (blockHash) => connectedBlocks.blocks.get(blockHash)?.header ?? null,
      isPinned: (blockHash) => !!connectedBlocks.blocks.get(blockHash)?.usages.has(subId),
      unpin
    };
  };
  const clean = () => {
    pendingBlocks.clear();
    connectedBlocks.blocks.clear();
  };
  return {
    clean,
    upstream,
    finalized$,
    getHeader$: (hash) => {
      const block = connectedBlocks.blocks.get(hash);
      return block ? rxjs.of(block) : getHeader$(hash);
    },
    hasher$
  };
};

const getFromShittyHeader = (hasher) => ({
  parentHash,
  number: rawNumber,
  stateRoot,
  extrinsicsRoot,
  digest
}) => {
  const number = Number(rawNumber);
  const rawDigests = digest.logs.map(utils.fromHex);
  const rawHeader = utils.mergeUint8([
    utils.fromHex(parentHash),
    substrateBindings.compact.enc(number),
    utils.fromHex(stateRoot),
    utils.fromHex(extrinsicsRoot),
    substrateBindings.compact.enc(digest.logs.length),
    ...rawDigests
  ]);
  return {
    parent: parentHash,
    hash: utils.toHex(hasher(rawHeader)),
    number,
    hasUpgrade: rawDigests.some(([x]) => x === 8),
    header: utils.toHex(rawHeader)
  };
};

const hashers = [substrateBindings.Blake2256, substrateBindings.Keccak256];
const fns = hashers.map(getFromShittyHeader);
const noHasher = (_) => {
  throw new Error("Hasher not supported");
};
const getHasherFromBlock = (shitHeader) => (hash) => hashers[fns.findIndex((fn) => fn(shitHeader).hash === hash)] || noHasher;

const withLatestFromBp = (latest$) => (base$) => new rxjs.Observable((observer) => {
  let latest;
  let prev = [];
  const subscription = base$.subscribe({
    next(v) {
      if (prev) prev.push(v);
      else observer.next([latest, v]);
    },
    error(e) {
      observer.error(e);
    },
    complete() {
      observer.complete();
    }
  });
  subscription.add(
    latest$.subscribe({
      next(v) {
        latest = v;
        if (prev) {
          const copy = [...prev];
          prev = null;
          copy.forEach((p) => observer.next([latest, p]));
        }
      },
      error(e) {
        observer.error(e);
      },
      complete() {
        if (prev) observer.error(new Error("Empty complete"));
      }
    })
  );
  return subscription;
});

const getUpstreamEvents = (request, request$) => {
  const firstFinHeader$ = new rxjs.Subject();
  const hasher$ = firstFinHeader$.pipe(
    rxjs.mergeMap(
      (h) => request$("chain_getBlockHash", [
        h.number
      ]).pipe(rxjs.map(getHasherFromBlock(h)))
    ),
    shareLatest
  );
  const fromShittyHeader$ = hasher$.pipe(rxjs.map(getFromShittyHeader), shareLatest);
  const toNiceHeader = rxjs.pipe(
    withLatestFromBp(fromShittyHeader$),
    rxjs.map(([fromShittyHeader, shitHeader]) => fromShittyHeader(shitHeader))
  );
  const getHeaders$ = (startMethod, stopMethod, isFin = false) => new rxjs.Observable((observer) => {
    const onError = (e) => {
      observer.error(e);
    };
    let stop = null;
    let isFirstFin = isFin;
    request(startMethod, [], {
      onSuccess: (subId, followSub) => {
        const done = followSub(subId, {
          next: (v) => {
            if (isFirstFin) {
              isFirstFin = false;
              firstFinHeader$.next(v);
              firstFinHeader$.complete();
            }
            observer.next(v);
          },
          error: onError
        });
        const unsubscribe = () => {
          done();
          try {
            request(stopMethod, [subId], {
              onError: utils.noop,
              onSuccess: utils.noop
            });
          } catch {
          }
        };
        if (stop !== null) unsubscribe();
        else stop = unsubscribe;
      },
      onError
    });
    return () => {
      stop?.();
      stop = utils.noop;
    };
  }).pipe(toNiceHeader);
  const allHeads$ = getHeaders$(
    "chain_subscribeAllHeads",
    "chain_unsubscribeAllHeads"
  );
  const finalized$ = getHeaders$(
    "chain_subscribeFinalizedHeads",
    "chain_unsubscribeFinalizedHeads",
    true
  );
  const getHeader$ = (hash) => request$("chain_getHeader", [hash]).pipe(
    toNiceHeader
  );
  const getRecursiveHeader = (hash) => getHeader$(hash).pipe(
    rxjs.mergeMap(
      (header) => rxjs.concat(rxjs.of(header), getRecursiveHeader(header.parent))
    )
  );
  return {
    allHeads$,
    finalized$,
    hasher$,
    getRecursiveHeader,
    getHeader$
  };
};

const getBlocks$ = (request, request$) => getBlocks(getUpstreamEvents(request, request$));

const createDescendantValues = (request) => {
  return (rootKey, at, onValues, onError, onDone) => {
    let isRunning = true;
    let areAllKeysDone = false;
    let onGoingValues = 0;
    const _onError = (e) => {
      if (isRunning) {
        isRunning = false;
        onError(e);
      }
    };
    const PAGE_SIZE = 1e3;
    const pullKeys = (startAtKey) => {
      request(
        "state_getKeysPaged",
        [rootKey, PAGE_SIZE, startAtKey || void 0, at],
        (result) => {
          if (!isRunning) return;
          if (result.length > 0) {
            onGoingValues++;
            request(
              "state_queryStorageAt",
              [result, at],
              ([{ changes }]) => {
                if (!isRunning) return;
                onGoingValues--;
                onValues(changes);
                if (areAllKeysDone && !onGoingValues) onDone();
              },
              _onError
            );
          }
          if (result.length < PAGE_SIZE) {
            areAllKeysDone = true;
            if (!onGoingValues) onDone();
          } else pullKeys(result.at(-1));
        },
        _onError
      );
    };
    pullKeys();
    return () => {
      isRunning = false;
    };
  };
};

const createClosestDescendantMerkleValue = (obsRequest) => (at, key) => obsRequest("state_getReadProof", [[key], at]).pipe(
  rxjs.mergeMap((x) => {
    const result = substrateBindings.validateProofs(x.proof);
    if (!result) throw new Error("Invalid Proof");
    const { rootHash, proofs } = result;
    let winnerHash = rootHash;
    let current = proofs[winnerHash];
    let nKeyChars = 2;
    do {
      const nextOne = proofs[winnerHash];
      if (!nextOne || nextOne.type === "Raw") break;
      current = nextOne;
      winnerHash = void 0;
      if (!current.partialKey.startsWith(
        key.slice(nKeyChars, nKeyChars + current.partialKey.length)
      ))
        return [];
      nKeyChars += current.partialKey.length;
      if ((current.type === "LeafWithHash" || current.type === "BranchWithHash") && proofs[current.value]) {
        winnerHash = current.value;
        continue;
      }
      if ("children" in current) {
        const winner = Object.entries(
          current.children
        ).find(([, hash]) => proofs[hash]);
        if (winner) {
          if (winner[0] !== key[nKeyChars++]) return [];
          winnerHash = winner[1];
        }
      }
    } while (winnerHash);
    return [current.hash];
  })
);

const createUpstream = (provider) => {
  const { request, disconnect } = rawClient.createClient(provider);
  const simpleRequest = (method, params, onSuccess, onError) => request(method, params, { onSuccess, onError });
  const obsRequest = (method, params) => new rxjs.Observable(
    (observer) => simpleRequest(
      method,
      params,
      (v) => {
        observer.next(v);
        observer.complete();
      },
      (e) => {
        observer.error(e);
      }
    )
  );
  const {
    upstream: getBlocks,
    finalized$,
    getHeader$,
    hasher$,
    clean
  } = getBlocks$(request, obsRequest);
  const runtimeCall = (atBlock, method, data) => obsRequest("state_call", [
    method,
    data,
    atBlock
  ]);
  const innerStgDescendantVals = createDescendantValues(simpleRequest);
  const stgDescendantValues = (at, rootKey) => new rxjs.Observable(
    (observer) => innerStgDescendantVals(
      rootKey,
      at,
      (values) => {
        observer.next(values);
      },
      (e) => {
        observer.error(e);
      },
      () => {
        observer.complete();
      }
    )
  );
  const stgDescendantHashes = (at, rootKey) => stgDescendantValues(at, rootKey).pipe(
    withLatestFromBp(hasher$),
    rxjs.map(
      ([hasher, results]) => results.map(
        ([key, value]) => [key, utils.toHex(hasher(utils.fromHex(value)))]
      )
    )
  );
  const stgClosestDescendant = createClosestDescendantMerkleValue(obsRequest);
  const [stgValue, stgHash] = ["state_getStorage", "state_getStorageHash"].map(
    (method) => (atBlock, key) => obsRequest(method, [
      key,
      atBlock
    ])
  );
  const methods = obsRequest("rpc_methods", []);
  const chainName = obsRequest("system_name", []);
  const properties = obsRequest("system_properties", []);
  const getBody = (at) => obsRequest(
    "chain_getBlock",
    [at]
  );
  const getBlockHash$ = (height) => obsRequest("chain_getBlockHash", [height]);
  const genesisHash = getBlockHash$(0);
  return {
    getBlocks,
    finalized$,
    getBlockHash$,
    getHeader$,
    stgValue,
    stgHash,
    stgDescendantValues,
    stgDescendantHashes,
    stgClosestDescendant,
    runtimeCall,
    getBody,
    chainName,
    properties,
    genesisHash,
    disconnect: () => {
      disconnect();
      clean();
    },
    methods,
    request: simpleRequest,
    obsRequest
  };
};

const chainSpecMethods = Object.fromEntries(
  ["chainName", "genesisHash", "properties"].map(
    (key) => [key, `chainSpec_v1_${key}`]
  )
);
const createChainSpec = (upstream, reply, err) => {
  return (rId, method) => {
    const [, , name] = method.split("_");
    const observable = upstream[name];
    if (!observable) throw null;
    observable.subscribe(
      (result) => {
        reply(rId, result);
      },
      () => {
        err(rId, -32602, "Invalid");
      }
    );
  };
};

let latestId = 1;
const createOpaqueToken = () => {
  return `${latestId++}${Date.now()}`;
};

const validStorageTypes = /* @__PURE__ */ new Set([
  "value",
  "hash",
  "closestDescendantMerkleValue",
  "descendantsValues",
  "descendantsHashes"
]);
const areItemsValid = (items) => Array.isArray(items) && items.every(
  (x) => typeof x === "object" && typeof x.key === "string" && validStorageTypes.has(x.type)
);
const getStg$ = (upstream, at, items) => rxjs.merge(
  ...items.map(({ key, type }) => {
    switch (type) {
      case "value":
        return upstream.stgValue(at, key).pipe(
          rxjs.filter(Boolean),
          rxjs.map((value) => [
            {
              key,
              value
            }
          ])
        );
      case "hash":
        return upstream.stgHash(at, key).pipe(
          rxjs.filter(Boolean),
          rxjs.map((hash) => [
            {
              key,
              hash
            }
          ])
        );
      case "descendantsValues":
        return upstream.stgDescendantValues(at, key).pipe(
          rxjs.map((values) => values.map(([key2, value]) => ({ key: key2, value })))
        );
      case "descendantsHashes":
        return upstream.stgDescendantHashes(at, key).pipe(rxjs.map((values) => values.map(([key2, hash]) => ({ key: key2, hash }))));
      case "closestDescendantMerkleValue":
        return upstream.stgClosestDescendant(at, key).pipe(
          rxjs.filter(Boolean),
          rxjs.map((closestDescendantMerkleValue) => [
            {
              key,
              closestDescendantMerkleValue
            }
          ])
        );
    }
  })
);

const getMsgFromErr = (e) => {
  if (e instanceof Error) return e.message;
  if (typeof e === "string") return e;
  return "Unhandled exception";
};

const chainHeadMethods = Object.fromEntries(
  [
    "body",
    "call",
    "continue",
    "follow",
    "header",
    "stopOperation",
    "storage",
    "unfollow",
    "unpin"
  ].map((key) => [key, `chainHead_v1_${key}`])
);
const createChainHead = (upstream, reply, err, notification) => {
  const subscriptions = /* @__PURE__ */ new Map();
  const follow = (rId) => {
    if (subscriptions.size === 2) {
      return err(rId, -32800, "Limit reached");
    }
    const token = createOpaqueToken();
    const up = upstream.getBlocks(token);
    const operations = /* @__PURE__ */ new Map();
    subscriptions.set(token, {
      id: token,
      up,
      operations,
      cleanUp: () => {
        cleanUp();
      }
    });
    let cleanUp = utils.noop;
    reply(rId, token);
    let subscription = up.blocks$.subscribe({
      next(v) {
        notification("chainHead_v1_followEvent", token, v);
      },
      error() {
        cleanUp();
        notification("chainHead_v1_followEvent", token, { event: "stop" });
      }
    });
    cleanUp = () => {
      cleanUp = utils.noop;
      subscription?.unsubscribe();
      subscription = null;
      operations.forEach((cb) => {
        cb();
      });
      operations.clear();
      subscriptions.delete(token);
    };
    if (subscription.closed) cleanUp();
  };
  const unfollow = (rId, followId) => {
    subscriptions.get(followId)?.cleanUp();
    reply(rId, "null");
  };
  const stopOperation = (rId, followId, operationId) => {
    const cb = subscriptions.get(followId)?.operations.get(operationId);
    if (cb) cb();
    reply(rId, "null");
  };
  const header = ({ up: { getHeader } }, reply2, at) => {
    reply2(getHeader(at));
  };
  const unpin = ({ up: { unpin: innerUnpin } }, reply2, hashOrHashes) => {
    const hashes = typeof hashOrHashes === "string" ? [hashOrHashes] : hashOrHashes;
    hashes.forEach(innerUnpin);
    reply2(null);
  };
  const call = ({ operations, id: followId }, reply2, at, method, args) => {
    const operationId = createOpaqueToken();
    reply2({ result: "started", operationId });
    const subscription = upstream.runtimeCall(at, method, args).subscribe(
      (output) => {
        operations.delete(operationId);
        notification("chainHead_v1_call", followId, {
          event: "operationCallDone",
          operationId,
          output
        });
      },
      (e) => {
        operations.delete(operationId);
        notification("chainHead_v1_call", followId, {
          event: "operationError",
          operationId,
          error: getMsgFromErr(e)
        });
      }
    );
    if (!subscription.closed)
      operations.set(operationId, () => {
        subscription.unsubscribe();
        operations.delete(operationId);
      });
  };
  const body = ({ operations, id: followId }, reply2, at) => {
    const operationId = createOpaqueToken();
    reply2({ result: "started", operationId });
    const subscription = upstream.getBody(at).subscribe(
      ({ block: { extrinsics: value } }) => {
        operations.delete(operationId);
        notification("chainHead_v1_body", followId, {
          event: "operationBodyDone",
          operationId,
          value
        });
      },
      (e) => {
        operations.delete(operationId);
        notification("chainHead_v1_body", followId, {
          event: "operationError",
          operationId,
          error: getMsgFromErr(e)
        });
      }
    );
    if (!subscription.closed)
      operations.set(operationId, () => {
        subscription.unsubscribe();
        operations.delete(operationId);
      });
  };
  const stg = ({ operations, id: followId }, reply2, at, items) => {
    const operationId = createOpaqueToken();
    reply2({ result: "started", operationId });
    const innerNotifiaction = (msg) => {
      notification("chainHead_v1_storage", followId, msg);
    };
    const subscription = getStg$(upstream, at, items).pipe(
      rxjs.finalize(() => {
        operations.delete(operationId);
      })
    ).subscribe(
      (items2) => {
        innerNotifiaction({
          event: "operationStorageItems",
          operationId,
          items: items2
        });
      },
      (e) => {
        innerNotifiaction({
          event: "operationError",
          operationId,
          error: getMsgFromErr(e)
        });
      },
      () => {
        innerNotifiaction({
          event: "operationStorageDone",
          operationId
        });
      }
    );
    if (!subscription.closed)
      operations.set(operationId, () => {
        subscription.unsubscribe();
      });
  };
  const result = (rId, method, params) => {
    if (method === chainHeadMethods.follow) return follow(rId);
    const [followId, ...rest] = params;
    const ctx = subscriptions.get(followId);
    if (!ctx) return err(rId, -32602, "Ivalid followSubscription");
    const innerReply = (value) => {
      reply(rId, value);
    };
    switch (method) {
      case chainHeadMethods.unfollow:
        return unfollow(rId, followId);
      case chainHeadMethods.stopOperation:
        return stopOperation(rId, followId, rest[0]);
      case chainHeadMethods.unpin: {
        const [hashOrHashes] = rest;
        if ((Array.isArray(hashOrHashes) ? hashOrHashes : [hashOrHashes]).some(
          (hash) => typeof hash !== "string"
        ))
          return err(rId, -32602, "Invalid args");
        return unpin(ctx, innerReply, hashOrHashes);
      }
      default: {
        const [at, ...other] = rest;
        if (!ctx.up.isPinned(at)) return err(rId, -32801, "Block not pinned");
        switch (method) {
          case chainHeadMethods.header:
            return header(ctx, innerReply, at);
          case chainHeadMethods.body:
            return body(ctx, innerReply, at);
          case chainHeadMethods.call: {
            const [method2, data] = other;
            if (typeof method2 !== "string" || typeof data !== "string")
              return err(rId, -32602, "Invalid args");
            return call(ctx, innerReply, at, method2, data);
          }
          case chainHeadMethods.storage: {
            const [items] = other;
            return areItemsValid(items) ? stg(ctx, innerReply, at, items) : err(rId, -32602, "Invalid args");
          }
        }
      }
    }
    throw null;
  };
  result.stop = () => {
    subscriptions.forEach((x) => {
      x.cleanUp();
    });
  };
  return result;
};

const transactionMethods = Object.fromEntries(
  ["broadcast", "stop"].map((key) => [key, `transaction_v1_${key}`])
);
const createTransactionFns = (upstream, reply) => {
  const ongoing = /* @__PURE__ */ new Map();
  const result = (rId, method, args) => {
    if (method === transactionMethods.stop) {
      const [token] = args;
      ongoing.get(token)?.unsubscribe();
      ongoing.delete(token);
      reply(rId, null);
    } else if (method === transactionMethods.broadcast) {
      const token = createOpaqueToken();
      ongoing.set(
        token,
        upstream.obsRequest("author_submitExtrinsic", args).pipe(
          // We want to make sure that we keep on retrying if there
          // are errors with the `author_submitExtrinsic` request
          rxjs.catchError((_, source) => rxjs.concat(rxjs.timer(5e3), source)),
          // This logic ensures that the subscription dies if an
          // upstream error (like the client being destroyed) takes place
          rxjs.takeUntil(
            upstream.finalized$.pipe(
              rxjs.ignoreElements(),
              rxjs.catchError(() => {
                ongoing.delete(token);
                return [null];
              })
            )
          )
        ).subscribe()
      );
      reply(rId, token);
    } else {
      throw null;
    }
  };
  result.stop = () => {
    ongoing.forEach((s) => s.unsubscribe());
    ongoing.clear();
  };
  return result;
};

const archiveMethods = Object.fromEntries(
  [
    "body",
    "call",
    "finalizedHeight",
    "genesisHash",
    "hashByHeight",
    "header",
    "stopStorage",
    "storage"
  ].map((key) => [key, `archive_v1_${key}`])
);
const createArchive = (upstream, reply, err, notification) => {
  const stgSubscriptions = /* @__PURE__ */ new Map();
  const stg = (reply2, at, items) => {
    const subId = createOpaqueToken();
    reply2(subId);
    const innerNotifiaction = (result2) => {
      notification("archive_v1_storageEvent", subId, result2);
    };
    const subscription = getStg$(upstream, at, items).pipe(
      rxjs.finalize(() => {
        stgSubscriptions.delete(subId);
      })
    ).subscribe(
      (items2) => {
        items2.forEach(
          (item) => innerNotifiaction({ event: "storage", ...item })
        );
      },
      (e) => {
        innerNotifiaction({ event: "storageError", error: getMsgFromErr(e) });
      },
      () => {
        innerNotifiaction({ event: "storageDone" });
      }
    );
    if (!subscription.closed) stgSubscriptions.set(subId, subscription);
  };
  const result = (rId, name, params) => {
    const innerReply = (value) => {
      reply(rId, value);
    };
    const obsReply = (input) => {
      input.subscribe({
        next: innerReply,
        error: (e) => {
          err(rId, e.code ?? -1, getMsgFromErr(e));
        }
      });
    };
    const [firstArg, secondArg, thirdArg] = params;
    switch (name) {
      case archiveMethods.body:
        return obsReply(upstream.getBody(firstArg));
      case archiveMethods.call:
        return obsReply(
          upstream.runtimeCall(firstArg, secondArg, thirdArg).pipe(rxjs.map((value) => ({ success: true, value })))
        );
      case archiveMethods.finalizedHeight:
        return obsReply(
          upstream.finalized$.pipe(
            rxjs.map((x) => x.number),
            rxjs.take(1)
          )
        );
      case archiveMethods.genesisHash:
        return obsReply(upstream.genesisHash);
      case archiveMethods.hashByHeight:
        return obsReply(upstream.getBlockHash$(firstArg));
      case archiveMethods.header:
        return obsReply(
          upstream.getHeader$(firstArg).pipe(rxjs.map((h) => h.header))
        );
      case archiveMethods.stopStorage: {
        const sub = stgSubscriptions.get(firstArg);
        return sub ? sub.unsubscribe() : err(rId, -32602, "Invalid args");
      }
      case archiveMethods.storage:
        return areItemsValid(secondArg) ? stg(innerReply, firstArg, secondArg) : err(rId, -32602, "Invalid args");
    }
    throw null;
  };
  result.stop = () => {
    [...stgSubscriptions].forEach(([, s]) => s.unsubscribe());
    stgSubscriptions.clear();
  };
  return result;
};

const withNumericIds = (base) => (onMsg) => {
  let nextId = 0;
  const numberToOriginal = /* @__PURE__ */ new Map();
  const { send: originalSend, disconnect } = base((msg) => {
    const { id, ...rest } = JSON.parse(msg);
    let actualMsg = msg;
    if (numberToOriginal.has(id)) {
      actualMsg = JSON.stringify({ ...rest, id: numberToOriginal.get(id) });
      numberToOriginal.delete(id);
    }
    onMsg(actualMsg);
  });
  return {
    send: (msg) => {
      const parsedMsg = JSON.parse(msg);
      let actualMsg = msg;
      if ("id" in parsedMsg) {
        const id = nextId++;
        numberToOriginal.set(id, parsedMsg.id);
        actualMsg = JSON.stringify({ ...parsedMsg, id });
      }
      originalSend(actualMsg);
    },
    disconnect
  };
};

const supportedMethods = [
  chainSpecMethods,
  archiveMethods,
  chainHeadMethods,
  transactionMethods
].map((methods) => Object.values(methods)).flat();
const createDownstream = () => (upstreamProvider) => {
  const upstream = createUpstream(withNumericIds(upstreamProvider));
  return (onMessage) => {
    const jsonRpc = (input) => onMessage(
      JSON.stringify({
        jsonrpc: "2.0",
        ...input
      })
    );
    const reply = (id, result) => {
      jsonRpc({ id, result });
    };
    const err = (id, code, message) => {
      jsonRpc({ id, error: { code, message } });
    };
    const notification = (method, subscription, result) => {
      jsonRpc({ method, params: { subscription, result } });
    };
    const groups = {
      chainSpec: createChainSpec(upstream, reply, err),
      chainHead: createChainHead(upstream, reply, err, notification),
      archive: createArchive(upstream, reply, err, notification),
      transaction: createTransactionFns(upstream, reply)
    };
    return {
      send: (msg) => {
        let parsedMsg = null;
        try {
          parsedMsg = JSON.parse(msg);
        } catch {
        }
        if (!parsedMsg) return;
        const { id, method, params } = parsedMsg;
        if (id !== null && typeof id !== "string" && typeof id !== "number" || typeof method !== "string") {
          console.warn(`Invalid message:
${msg}`);
          return;
        }
        if (method === "rpc_methods") {
          return upstream.methods.subscribe(
            ({ methods }) => {
              reply(id, {
                methods: [
                  ...supportedMethods,
                  ...methods.filter(
                    (method2) => !supportedMethods.includes(method2)
                  )
                ]
              });
            },
            (e) => {
              console.error(e);
              err(id, -32602, "Invalid");
            }
          );
        }
        const [groupName] = method.split("_");
        if (groupName in groups) {
          try {
            return groups[groupName](
              id,
              method,
              params
            );
          } catch (e) {
            if (e !== null) throw e;
          }
        }
        upstream.request(
          method,
          params,
          (value) => {
            reply(id, value);
          },
          (e) => {
            err(id, e?.code || -1, e?.message || "");
          }
        );
      },
      disconnect: () => {
        groups.chainHead.stop();
        groups.archive.stop();
        groups.transaction.stop();
        upstream.disconnect();
      }
    };
  };
};

const withLegacy = createDownstream;

exports.withLegacy = withLegacy;
//# sourceMappingURL=index.js.map
